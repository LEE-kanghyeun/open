{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import urllib\n",
    "import ssl\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset  \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from copy import deepcopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에러 : <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1108)>\n",
    "# https://stackoverflow.com/questions/69687794/unable-to-manually-load-cifar10-dataset\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "### 데이터 세팅\n",
    "\n",
    "\n",
    "## Transform 선언\n",
    "random_choice = transforms.RandomChoice([transforms.RandomRotation((0,40)),\n",
    "                                        transforms.RandomVerticalFlip(0.5),\n",
    "                                        transforms.RandomHorizontalFlip(0.5)])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#              transforms.Resize(224),\n",
    "            random_choice,\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "## Transform 선언\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, \n",
    "#                                         transform=transforms.ToTensor(),\n",
    "                                        transform = transform\n",
    "                                       )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, \n",
    "                                       transform=transforms.ToTensor(),\n",
    "#                                        transform = transform\n",
    "                                      )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(trainset.data[2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(trainset.data[1])\n",
    "plt.show()\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 로 적용됩니다\n",
      "총 배치의 수 : 12500\n",
      "[Epoch:    0] cost = 2.17894006, trigger_n: 0, best_epoch: 0\n",
      "[Epoch:    1] cost = 2.01864171, trigger_n: 0, best_epoch: 1\n",
      "[Epoch:    2] cost = 1.9343276, trigger_n: 0, best_epoch: 2\n",
      "[Epoch:    3] cost = 1.8554492, trigger_n: 0, best_epoch: 3\n",
      "[Epoch:    4] cost = 1.80749834, trigger_n: 0, best_epoch: 4\n",
      "[Epoch:    5] cost = 1.77388334, trigger_n: 0, best_epoch: 5\n",
      "[Epoch:    6] cost = 1.75411141, trigger_n: 0, best_epoch: 6\n",
      "[Epoch:    7] cost = 1.71029031, trigger_n: 0, best_epoch: 7\n",
      "[Epoch:    8] cost = 1.69182444, trigger_n: 0, best_epoch: 8\n",
      "[Epoch:    9] cost = 1.6682173, trigger_n: 0, best_epoch: 9\n",
      "[Epoch:   10] cost = 1.64430559, trigger_n: 0, best_epoch: 10\n",
      "[Epoch:   11] cost = 1.62479699, trigger_n: 0, best_epoch: 11\n",
      "[Epoch:   12] cost = 1.61073577, trigger_n: 0, best_epoch: 12\n",
      "[Epoch:   13] cost = 1.58826625, trigger_n: 0, best_epoch: 13\n",
      "[Epoch:   14] cost = 1.58234036, trigger_n: 0, best_epoch: 14\n",
      "[Epoch:   15] cost = 1.55368018, trigger_n: 0, best_epoch: 15\n",
      "[Epoch:   16] cost = 1.55702734, trigger_n: 1, best_epoch: 15\n",
      "[Epoch:   17] cost = 1.58481038, trigger_n: 2, best_epoch: 15\n",
      "[Epoch:   18] cost = 1.55870295, trigger_n: 3, best_epoch: 15\n",
      "[Epoch:   19] cost = 1.53171146, trigger_n: 0, best_epoch: 19\n",
      "[Epoch:   20] cost = 1.52515268, trigger_n: 0, best_epoch: 20\n",
      "[Epoch:   21] cost = 1.51938927, trigger_n: 0, best_epoch: 21\n",
      "[Epoch:   22] cost = 1.50470233, trigger_n: 0, best_epoch: 22\n",
      "[Epoch:   23] cost = 1.49546087, trigger_n: 0, best_epoch: 23\n",
      "[Epoch:   24] cost = 1.49794745, trigger_n: 1, best_epoch: 23\n",
      "[Epoch:   25] cost = 1.47403824, trigger_n: 0, best_epoch: 25\n",
      "[Epoch:   26] cost = 1.47514129, trigger_n: 1, best_epoch: 25\n",
      "[Epoch:   27] cost = 1.46371555, trigger_n: 0, best_epoch: 27\n",
      "[Epoch:   28] cost = 1.45026374, trigger_n: 0, best_epoch: 28\n",
      "[Epoch:   29] cost = 1.44905007, trigger_n: 0, best_epoch: 29\n",
      "[Epoch:   30] cost = 1.44883597, trigger_n: 0, best_epoch: 30\n",
      "[Epoch:   31] cost = 1.43710172, trigger_n: 0, best_epoch: 31\n",
      "[Epoch:   32] cost = 1.42725658, trigger_n: 0, best_epoch: 32\n",
      "[Epoch:   33] cost = 1.4217875, trigger_n: 0, best_epoch: 33\n",
      "[Epoch:   34] cost = 1.42233217, trigger_n: 1, best_epoch: 33\n",
      "[Epoch:   35] cost = 1.41803598, trigger_n: 0, best_epoch: 35\n",
      "[Epoch:   36] cost = 1.42608631, trigger_n: 1, best_epoch: 35\n",
      "[Epoch:   37] cost = 1.40793049, trigger_n: 0, best_epoch: 37\n",
      "[Epoch:   38] cost = 1.40732086, trigger_n: 0, best_epoch: 38\n",
      "[Epoch:   39] cost = 1.39928401, trigger_n: 0, best_epoch: 39\n",
      "[Epoch:   40] cost = 1.39970028, trigger_n: 1, best_epoch: 39\n",
      "[Epoch:   41] cost = 1.38914597, trigger_n: 0, best_epoch: 41\n",
      "[Epoch:   42] cost = 1.38801026, trigger_n: 0, best_epoch: 42\n",
      "[Epoch:   43] cost = 1.39457738, trigger_n: 1, best_epoch: 42\n",
      "[Epoch:   44] cost = 1.38397551, trigger_n: 0, best_epoch: 44\n",
      "[Epoch:   45] cost = 1.40410542, trigger_n: 1, best_epoch: 44\n",
      "[Epoch:   46] cost = 1.37497818, trigger_n: 0, best_epoch: 46\n",
      "[Epoch:   47] cost = 1.37425637, trigger_n: 0, best_epoch: 47\n",
      "[Epoch:   48] cost = 1.39416039, trigger_n: 1, best_epoch: 47\n",
      "[Epoch:   49] cost = 1.38086247, trigger_n: 2, best_epoch: 47\n",
      "[Epoch:   50] cost = 1.37754393, trigger_n: 3, best_epoch: 47\n",
      "[Epoch:   51] cost = 1.3683219, trigger_n: 0, best_epoch: 51\n",
      "[Epoch:   52] cost = 1.35746384, trigger_n: 0, best_epoch: 52\n",
      "[Epoch:   53] cost = 1.35907996, trigger_n: 1, best_epoch: 52\n",
      "[Epoch:   54] cost = 1.35926771, trigger_n: 2, best_epoch: 52\n",
      "[Epoch:   55] cost = 1.35327065, trigger_n: 0, best_epoch: 55\n",
      "[Epoch:   56] cost = 1.34204125, trigger_n: 0, best_epoch: 56\n",
      "[Epoch:   57] cost = 1.35210419, trigger_n: 1, best_epoch: 56\n",
      "[Epoch:   58] cost = 1.35512555, trigger_n: 2, best_epoch: 56\n",
      "[Epoch:   59] cost = 1.34309387, trigger_n: 3, best_epoch: 56\n",
      "[Epoch:   60] cost = 1.36355984, trigger_n: 4, best_epoch: 56\n",
      "[Epoch:   61] cost = 1.34466743, trigger_n: 5, best_epoch: 56\n",
      "[Epoch:   62] cost = 1.34059942, trigger_n: 0, best_epoch: 62\n",
      "[Epoch:   63] cost = 1.32832623, trigger_n: 0, best_epoch: 63\n",
      "[Epoch:   64] cost = 1.33526623, trigger_n: 1, best_epoch: 63\n",
      "[Epoch:   65] cost = 1.32907343, trigger_n: 2, best_epoch: 63\n",
      "[Epoch:   66] cost = 1.32800543, trigger_n: 0, best_epoch: 66\n",
      "[Epoch:   67] cost = 1.32671344, trigger_n: 0, best_epoch: 67\n",
      "[Epoch:   68] cost = 1.32137334, trigger_n: 0, best_epoch: 68\n",
      "[Epoch:   69] cost = 1.3169874, trigger_n: 0, best_epoch: 69\n",
      "[Epoch:   70] cost = 1.31952226, trigger_n: 1, best_epoch: 69\n",
      "[Epoch:   71] cost = 1.3293097, trigger_n: 2, best_epoch: 69\n",
      "[Epoch:   72] cost = 1.30423939, trigger_n: 0, best_epoch: 72\n",
      "[Epoch:   73] cost = 1.31414139, trigger_n: 1, best_epoch: 72\n",
      "[Epoch:   74] cost = 1.31248593, trigger_n: 2, best_epoch: 72\n",
      "[Epoch:   75] cost = 1.3327229, trigger_n: 3, best_epoch: 72\n",
      "[Epoch:   76] cost = 1.31325591, trigger_n: 4, best_epoch: 72\n",
      "[Epoch:   77] cost = 1.30864811, trigger_n: 5, best_epoch: 72\n",
      "[Epoch:   78] cost = 1.30190718, trigger_n: 0, best_epoch: 78\n",
      "[Epoch:   79] cost = 1.29810762, trigger_n: 0, best_epoch: 79\n",
      "[Epoch:   80] cost = 1.29976261, trigger_n: 1, best_epoch: 79\n",
      "[Epoch:   81] cost = 1.30178165, trigger_n: 2, best_epoch: 79\n",
      "[Epoch:   82] cost = 1.29949749, trigger_n: 3, best_epoch: 79\n",
      "[Epoch:   83] cost = 1.28542292, trigger_n: 0, best_epoch: 83\n",
      "[Epoch:   84] cost = 1.29287708, trigger_n: 1, best_epoch: 83\n",
      "[Epoch:   85] cost = 1.29332638, trigger_n: 2, best_epoch: 83\n",
      "[Epoch:   86] cost = 1.2972213, trigger_n: 3, best_epoch: 83\n",
      "[Epoch:   87] cost = 1.30461574, trigger_n: 4, best_epoch: 83\n",
      "[Epoch:   88] cost = 1.2831434, trigger_n: 0, best_epoch: 88\n",
      "[Epoch:   89] cost = 1.27963042, trigger_n: 0, best_epoch: 89\n",
      "[Epoch:   90] cost = 1.28879178, trigger_n: 1, best_epoch: 89\n",
      "[Epoch:   91] cost = 1.27711153, trigger_n: 0, best_epoch: 91\n",
      "[Epoch:   92] cost = 1.28248239, trigger_n: 1, best_epoch: 91\n",
      "[Epoch:   93] cost = 1.27789474, trigger_n: 2, best_epoch: 91\n",
      "[Epoch:   94] cost = 1.27728355, trigger_n: 3, best_epoch: 91\n",
      "[Epoch:   95] cost = 1.28476298, trigger_n: 4, best_epoch: 91\n",
      "[Epoch:   96] cost = 1.28213561, trigger_n: 5, best_epoch: 91\n",
      "[Epoch:   97] cost = 1.28027952, trigger_n: 6, best_epoch: 91\n",
      "[Epoch:   98] cost = 1.27303565, trigger_n: 0, best_epoch: 98\n",
      "[Epoch:   99] cost = 1.2711556, trigger_n: 0, best_epoch: 99\n",
      "[Epoch:  100] cost = 1.28210771, trigger_n: 1, best_epoch: 99\n",
      "[Epoch:  101] cost = 1.27844942, trigger_n: 2, best_epoch: 99\n",
      "[Epoch:  102] cost = 1.26238775, trigger_n: 0, best_epoch: 102\n",
      "[Epoch:  103] cost = 1.2646029, trigger_n: 1, best_epoch: 102\n",
      "[Epoch:  104] cost = 1.26945424, trigger_n: 2, best_epoch: 102\n",
      "[Epoch:  105] cost = 1.26602471, trigger_n: 3, best_epoch: 102\n",
      "[Epoch:  106] cost = 1.26963234, trigger_n: 4, best_epoch: 102\n",
      "[Epoch:  107] cost = 1.26093423, trigger_n: 0, best_epoch: 107\n",
      "[Epoch:  108] cost = 1.25600576, trigger_n: 0, best_epoch: 108\n",
      "[Epoch:  109] cost = 1.26578319, trigger_n: 1, best_epoch: 108\n",
      "[Epoch:  110] cost = 1.25246632, trigger_n: 0, best_epoch: 110\n",
      "[Epoch:  111] cost = 1.25293815, trigger_n: 1, best_epoch: 110\n",
      "[Epoch:  112] cost = 1.25836205, trigger_n: 2, best_epoch: 110\n",
      "[Epoch:  113] cost = 1.26588452, trigger_n: 3, best_epoch: 110\n",
      "[Epoch:  114] cost = 1.25899351, trigger_n: 4, best_epoch: 110\n",
      "[Epoch:  115] cost = 1.25812352, trigger_n: 5, best_epoch: 110\n",
      "[Epoch:  116] cost = 1.24821496, trigger_n: 0, best_epoch: 116\n",
      "[Epoch:  117] cost = 1.25243735, trigger_n: 1, best_epoch: 116\n",
      "[Epoch:  118] cost = 1.24802864, trigger_n: 0, best_epoch: 118\n",
      "[Epoch:  119] cost = 1.25242007, trigger_n: 1, best_epoch: 118\n",
      "[Epoch:  120] cost = 1.24688244, trigger_n: 0, best_epoch: 120\n",
      "[Epoch:  121] cost = 1.23963904, trigger_n: 0, best_epoch: 121\n",
      "[Epoch:  122] cost = 1.23702002, trigger_n: 0, best_epoch: 122\n",
      "[Epoch:  123] cost = 1.23930275, trigger_n: 1, best_epoch: 122\n",
      "[Epoch:  124] cost = 1.24488723, trigger_n: 2, best_epoch: 122\n",
      "[Epoch:  125] cost = 1.24662173, trigger_n: 3, best_epoch: 122\n",
      "[Epoch:  126] cost = 1.24380183, trigger_n: 4, best_epoch: 122\n",
      "[Epoch:  127] cost = 1.24603117, trigger_n: 5, best_epoch: 122\n",
      "[Epoch:  128] cost = 1.23951697, trigger_n: 6, best_epoch: 122\n",
      "[Epoch:  129] cost = 1.24179959, trigger_n: 7, best_epoch: 122\n",
      "[Epoch:  130] cost = 1.2385385, trigger_n: 8, best_epoch: 122\n",
      "[Epoch:  131] cost = 1.23200417, trigger_n: 0, best_epoch: 131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  132] cost = 1.23776984, trigger_n: 1, best_epoch: 131\n",
      "[Epoch:  133] cost = 1.23835325, trigger_n: 2, best_epoch: 131\n",
      "[Epoch:  134] cost = 1.23637569, trigger_n: 3, best_epoch: 131\n",
      "[Epoch:  135] cost = 1.23050332, trigger_n: 0, best_epoch: 135\n",
      "[Epoch:  136] cost = 1.23706007, trigger_n: 1, best_epoch: 135\n",
      "[Epoch:  137] cost = 1.23738945, trigger_n: 2, best_epoch: 135\n",
      "[Epoch:  138] cost = 1.22784913, trigger_n: 0, best_epoch: 138\n",
      "[Epoch:  139] cost = 1.23823154, trigger_n: 1, best_epoch: 138\n",
      "[Epoch:  140] cost = 1.23206592, trigger_n: 2, best_epoch: 138\n",
      "[Epoch:  141] cost = 1.2304827, trigger_n: 3, best_epoch: 138\n",
      "[Epoch:  142] cost = 1.22723913, trigger_n: 0, best_epoch: 142\n",
      "[Epoch:  143] cost = 1.22150111, trigger_n: 0, best_epoch: 143\n",
      "[Epoch:  144] cost = 1.23898411, trigger_n: 1, best_epoch: 143\n",
      "[Epoch:  145] cost = 1.21488523, trigger_n: 0, best_epoch: 145\n",
      "[Epoch:  146] cost = 1.24376595, trigger_n: 1, best_epoch: 145\n",
      "[Epoch:  147] cost = 1.22561431, trigger_n: 2, best_epoch: 145\n",
      "[Epoch:  148] cost = 1.22124791, trigger_n: 3, best_epoch: 145\n",
      "[Epoch:  149] cost = 1.22715521, trigger_n: 4, best_epoch: 145\n",
      "[Epoch:  150] cost = 1.21271133, trigger_n: 0, best_epoch: 150\n",
      "[Epoch:  151] cost = 1.21819723, trigger_n: 1, best_epoch: 150\n",
      "[Epoch:  152] cost = 1.22802889, trigger_n: 2, best_epoch: 150\n",
      "[Epoch:  153] cost = 1.2248143, trigger_n: 3, best_epoch: 150\n",
      "[Epoch:  154] cost = 1.21799266, trigger_n: 4, best_epoch: 150\n",
      "[Epoch:  155] cost = 1.22243989, trigger_n: 5, best_epoch: 150\n",
      "[Epoch:  156] cost = 1.22262824, trigger_n: 6, best_epoch: 150\n",
      "[Epoch:  157] cost = 1.21723974, trigger_n: 7, best_epoch: 150\n",
      "[Epoch:  158] cost = 1.2255286, trigger_n: 8, best_epoch: 150\n",
      "[Epoch:  159] cost = 1.21065366, trigger_n: 0, best_epoch: 159\n",
      "[Epoch:  160] cost = 1.21592891, trigger_n: 1, best_epoch: 159\n",
      "[Epoch:  161] cost = 1.21450353, trigger_n: 2, best_epoch: 159\n",
      "[Epoch:  162] cost = 1.21683145, trigger_n: 3, best_epoch: 159\n",
      "[Epoch:  163] cost = 1.21233666, trigger_n: 4, best_epoch: 159\n",
      "[Epoch:  164] cost = 1.21468627, trigger_n: 5, best_epoch: 159\n",
      "[Epoch:  165] cost = 1.20375347, trigger_n: 0, best_epoch: 165\n",
      "[Epoch:  166] cost = 1.21227193, trigger_n: 1, best_epoch: 165\n",
      "[Epoch:  167] cost = 1.20947134, trigger_n: 2, best_epoch: 165\n",
      "[Epoch:  168] cost = 1.23745406, trigger_n: 3, best_epoch: 165\n",
      "[Epoch:  169] cost = 1.21313179, trigger_n: 4, best_epoch: 165\n",
      "[Epoch:  170] cost = 1.20882607, trigger_n: 5, best_epoch: 165\n",
      "[Epoch:  171] cost = 1.21050334, trigger_n: 6, best_epoch: 165\n",
      "[Epoch:  172] cost = 1.2061137, trigger_n: 7, best_epoch: 165\n",
      "[Epoch:  173] cost = 1.20889711, trigger_n: 8, best_epoch: 165\n",
      "[Epoch:  174] cost = 1.20770168, trigger_n: 9, best_epoch: 165\n",
      "[Epoch:  175] cost = 1.20637691, trigger_n: 10, best_epoch: 165\n",
      "[Epoch:  176] cost = 1.20593917, trigger_n: 11, best_epoch: 165\n",
      "[Epoch:  177] cost = 1.20201635, trigger_n: 0, best_epoch: 177\n",
      "[Epoch:  178] cost = 1.20341742, trigger_n: 1, best_epoch: 177\n",
      "[Epoch:  179] cost = 1.20268214, trigger_n: 2, best_epoch: 177\n",
      "[Epoch:  180] cost = 1.20042896, trigger_n: 0, best_epoch: 180\n",
      "[Epoch:  181] cost = 1.19877529, trigger_n: 0, best_epoch: 181\n",
      "[Epoch:  182] cost = 1.20171487, trigger_n: 1, best_epoch: 181\n",
      "[Epoch:  183] cost = 1.20143318, trigger_n: 2, best_epoch: 181\n",
      "[Epoch:  184] cost = 1.20579004, trigger_n: 3, best_epoch: 181\n",
      "[Epoch:  185] cost = 1.19946241, trigger_n: 4, best_epoch: 181\n",
      "[Epoch:  186] cost = 1.20038378, trigger_n: 5, best_epoch: 181\n",
      "[Epoch:  187] cost = 1.19773495, trigger_n: 0, best_epoch: 187\n",
      "[Epoch:  188] cost = 1.19311309, trigger_n: 0, best_epoch: 188\n",
      "[Epoch:  189] cost = 1.18963432, trigger_n: 0, best_epoch: 189\n",
      "[Epoch:  190] cost = 1.19299972, trigger_n: 1, best_epoch: 189\n",
      "[Epoch:  191] cost = 1.21108818, trigger_n: 2, best_epoch: 189\n",
      "[Epoch:  192] cost = 1.19421017, trigger_n: 3, best_epoch: 189\n",
      "[Epoch:  193] cost = 1.19670498, trigger_n: 4, best_epoch: 189\n",
      "[Epoch:  194] cost = 1.19140506, trigger_n: 5, best_epoch: 189\n",
      "[Epoch:  195] cost = 1.19987786, trigger_n: 6, best_epoch: 189\n",
      "[Epoch:  196] cost = 1.19573724, trigger_n: 7, best_epoch: 189\n",
      "[Epoch:  197] cost = 1.19927907, trigger_n: 8, best_epoch: 189\n",
      "[Epoch:  198] cost = 1.19091487, trigger_n: 9, best_epoch: 189\n",
      "[Epoch:  199] cost = 1.19459748, trigger_n: 10, best_epoch: 189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 딥한 CNN으로 MNIST 분류   (Early Stop 적용 / Dropout / batchnorm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device,'로 적용됩니다')\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "    \n",
    "learning_rate = 0.01\n",
    "training_epochs = 200\n",
    "batch_size = 100\n",
    "patience = 20  ## 얼리스탑 인자\n",
    "trigger_n = 0\n",
    "lowest_cost = np.inf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CNN 모델 클래스\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        # L1 ImgIn shape=(?, 32, 32, 3)\n",
    "        #    Conv     -> (?, 32, 32, 32)\n",
    "        #    Pool     -> (?, 16, 16, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # L2 ImgIn shape=(?, 16, 16, 32)\n",
    "        #    Conv      ->(?, 16, 16, 64)\n",
    "        #    Pool      ->(?, 8, 8, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # L3 ImgIn shape=(?, 8, 8, 64)\n",
    "        #    Conv      ->(?, 8, 8, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.kaiming_normal_( self.fc1.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "#         torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(625),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "            \n",
    "        \n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.kaiming_normal_( self.fc2.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "#         torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "                    self.fc2,\n",
    "                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "# CNN 모델 정의\n",
    "model = CNN().to(device)\n",
    "    \n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "total_batch = len(trainloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for X, Y in trainloader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    ## Early stopping\n",
    "    \n",
    "    current_cost = avg_cost\n",
    "    \n",
    "    # best model check\n",
    "    if current_cost < lowest_cost :\n",
    "        best_epoch = epoch\n",
    "        lowest_cost = current_cost\n",
    "        best_model = deepcopy(model.state_dict())\n",
    "        trigger_n = 0\n",
    "        \n",
    "    else:\n",
    "        trigger_n += 1\n",
    "        if trigger_n >= patience:\n",
    "            print(\"There is no improvement during last %d epochs.\" % trigger_n)\n",
    "            break\n",
    "#     https://blog.naver.com/1012rnjsdydgns/222458085542 참고\n",
    "\n",
    "\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}, trigger_n: {}, best_epoch: {}'.format(epoch , avg_cost, trigger_n, best_epoch))    \n",
    "  \n",
    "\n",
    "  \n",
    "# Load best epoch's model\n",
    "model.load_state_dict(best_model)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (DataLoader, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_16772/1680996794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     Y_val = torch.FloatTensor(y_val).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_16772/3618378101.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\user_LKH\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (DataLoader, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    model.eval()   ## 배치놈 인퍼런스 계산까지 포함됨 (평균, 편차, 감마, 베타 모두)\n",
    "    \n",
    "#     X_val = torch.FloatTensor(x_val).view(len(x_val), 1, 28, 28).float().to(device)\n",
    "#     Y_val = torch.FloatTensor(y_val).to(device)\n",
    "\n",
    "    prediction = model(testloader)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_val\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
